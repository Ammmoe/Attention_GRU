{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.trajectory_loader import load_and_concat_flights\n",
    "from models.attention_gru_predictor import TrajPredictor\n",
    "from utils.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044612ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "LOOK_BACK = 50\n",
    "FORWARD_LEN = 5\n",
    "CSV_PATH = \"data/flights.csv\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "AGENTS = 3  # Number of agents in the trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup logger and experiment folder ---\n",
    "logger, exp_dir = get_logger()\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "logger.info(\"Experiment started\")\n",
    "logger.info(\"Experiment folder: %s\", exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load DataFrame ---\n",
    "df = load_and_concat_flights(\n",
    "    CSV_PATH,\n",
    "    min_rows=800,\n",
    "    num_flights=AGENTS,\n",
    "    add_zurich_csv=True,\n",
    "    zurich_csv_path=\"data/zurich_flights_downsampled_2.csv\",\n",
    ")\n",
    "\n",
    "print(df.tail())\n",
    "\n",
    "# --- Prepare sequences ---\n",
    "X, y, trajectory_ids = [], [], []\n",
    "\n",
    "for traj_idx in df[\"trajectory_index\"].unique():\n",
    "    traj_df = df[df[\"trajectory_index\"] == traj_idx].reset_index(drop=True)\n",
    "\n",
    "    # Drop trajectory_index for features\n",
    "    traj_data = traj_df.drop(columns=[\"trajectory_index\"]).values.astype(np.float32)\n",
    "    n_rows = traj_data.shape[0]\n",
    "\n",
    "    seq_count = n_rows - LOOK_BACK - FORWARD_LEN + 1\n",
    "    for i in range(seq_count):\n",
    "        seq_X = traj_data[i : i + LOOK_BACK]  # shape (LOOK_BACK, features)\n",
    "        seq_y = traj_data[i + LOOK_BACK + FORWARD_LEN - 1]  # shape (features,)\n",
    "\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        trajectory_ids.append(traj_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convert to NumPy arrays ---\n",
    "X = np.array(X, dtype=np.float32)  # (num_sequences, LOOK_BACK, features)\n",
    "y = np.array(y, dtype=np.float32)  # (num_sequences, features)\n",
    "trajectory_ids = np.array(trajectory_ids)\n",
    "\n",
    "# --- Split train/test ---\n",
    "X_train, X_test, y_train, y_test, traj_train, traj_test = train_test_split(\n",
    "    X, y, trajectory_ids, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "num_features_X = X_train.shape[-1]\n",
    "\n",
    "# --- Scale column by column (concise approach) ---\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "scaler_X.fit(X_train.reshape(-1, num_features_X))\n",
    "X_train_scaled = scaler_X.transform(X_train.reshape(-1, num_features_X)).reshape(\n",
    "    X_train.shape\n",
    ")\n",
    "X_test_scaled = scaler_X.transform(X_test.reshape(-1, num_features_X)).reshape(\n",
    "    X_test.shape\n",
    ")\n",
    "\n",
    "scaler_y.fit(y_train)\n",
    "y_train_scaled = scaler_y.transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "# --- Convert to tensors ---\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# --- Create DataLoaders ---\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train_tensor, y_train_tensor), batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(X_test_tensor, y_test_tensor), batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922def7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log dataset sizes ---\n",
    "total_sequences = X_train_tensor.shape[0] + X_test_tensor.shape[0]\n",
    "logger.info(\"Total sequences: %d\", total_sequences)\n",
    "logger.info(\"Train sequences: %s\", X_train_tensor.shape)\n",
    "logger.info(\"Test sequences: %s\", X_test_tensor.shape)\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(\"Using device: %s\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model, criterion, optimizer ---\n",
    "model_params = {\n",
    "    \"input_size\": X_train_tensor.shape[-1],  # features (e.g., 3 for x,y,z)\n",
    "    \"hidden_size\": 64,\n",
    "    \"output_size\": y_train_tensor.shape[-1],  # same as features\n",
    "    \"num_layers\": 2,\n",
    "}\n",
    "\n",
    "model = TrajPredictor(**model_params).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "logger.info(\"Model initialized:\\n%s\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c35e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training ---\n",
    "patience = 15\n",
    "best_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "training_start = time.time()\n",
    "\n",
    "try:\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch_x)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        logger.info(\"Epoch %d/%d - Train Loss: %.7f\", epoch + 1, EPOCHS, avg_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), os.path.join(exp_dir, \"best_model.pt\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            logger.info(\"Early stopping triggered after %d epochs\", epoch + 1)\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.warning(\"Training interrupted by user! Running evaluation...\")\n",
    "\n",
    "# --- Save last-epoch model ---\n",
    "finally:\n",
    "    torch.save(model.state_dict(), os.path.join(exp_dir, \"last_model.pt\"))\n",
    "    logger.info(\"Training completed in %.2f seconds\", time.time() - training_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation ---\n",
    "model.eval()\n",
    "all_preds, all_trues = [], []\n",
    "inference_times = []\n",
    "total_sequences = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        total_sequences += batch_x.size(0)\n",
    "\n",
    "        start_time = time.time()\n",
    "        outputs = model(batch_x)\n",
    "        inference_times.append(time.time() - start_time)\n",
    "\n",
    "        all_preds.append(outputs.cpu())\n",
    "        all_trues.append(batch_y.cpu())\n",
    "\n",
    "# Concatenate all batches\n",
    "y_pred = torch.cat(all_preds, dim=0)\n",
    "y_true = torch.cat(all_trues, dim=0)\n",
    "\n",
    "# Inference time\n",
    "total_inf_time = sum(inference_times)\n",
    "logger.info(\n",
    "    \"Average inference time per sequence: %.6f s\", total_inf_time / total_sequences\n",
    ")\n",
    "logger.info(\n",
    "    \"Average inference time per batch: %.6f s\", total_inf_time / len(test_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config / hyperparameters\n",
    "config = {\n",
    "    \"device\": str(device),\n",
    "    \"model_params\": model_params,\n",
    "    \"LOOK_BACK\": LOOK_BACK,\n",
    "    \"FORWARD_LEN\": FORWARD_LEN,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "}\n",
    "\n",
    "config_path = os.path.join(exp_dir, \"config.json\")\n",
    "with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "logger.info(\"Config saved to %s\", config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Group results back by trajectory_index ---\n",
    "traj_test = traj_test[: len(y_true)]  # align just in case\n",
    "\n",
    "NUM_PLOTS = 3  # number of trajectories to plot\n",
    "unique_trajs = np.unique(traj_test)\n",
    "\n",
    "# Dynamically generate N colors from a colormap\n",
    "COLORS = [plt.get_cmap(\"tab10\")(i % 10) for i in range(AGENTS)]\n",
    "\n",
    "# Randomly select trajectories to plot\n",
    "plot_trajs = np.random.choice(\n",
    "    unique_trajs, size=min(NUM_PLOTS, len(unique_trajs)), replace=False\n",
    ")\n",
    "\n",
    "for traj_idx in plot_trajs:\n",
    "    mask = traj_test == traj_idx\n",
    "    true_traj = scaler_y.inverse_transform(y_true[mask].numpy())\n",
    "    pred_traj = scaler_y.inverse_transform(y_pred[mask].numpy())\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    DIM = 3  # 3D plot\n",
    "    for agent in range(AGENTS):\n",
    "        start = agent * DIM\n",
    "        end = start + DIM\n",
    "\n",
    "        # True trajectory for this agent\n",
    "        ax.plot(\n",
    "            true_traj[:, start],\n",
    "            true_traj[:, start + 1],\n",
    "            true_traj[:, start + 2],\n",
    "            label=f\"Agent {agent + 1} True\",\n",
    "            color=COLORS[agent],\n",
    "        )\n",
    "\n",
    "        # Predicted trajectory for this agent\n",
    "        ax.plot(\n",
    "            pred_traj[:, start],\n",
    "            pred_traj[:, start + 1],\n",
    "            pred_traj[:, start + 2],\n",
    "            label=f\"Agent {agent + 1} Pred\",\n",
    "            color=COLORS[agent],\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "    ax.set_title(f\"Trajectory {traj_idx} (True vs Predicted)\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_label(\"Z\")\n",
    "    ax.legend()\n",
    "\n",
    "    # --- Save PNGs ---\n",
    "    plot_path = os.path.join(exp_dir, f\"trajectory_{traj_idx}.png\")\n",
    "    plt.savefig(plot_path, dpi=150)\n",
    "\n",
    "    # --- For interactive viewing ---\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    logger.info(\"Plotted trajectory %s\", traj_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

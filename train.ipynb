{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.trajectory_loader import load_dataset\n",
    "from models.attention_bi_gru_predictor import TrajPredictor\n",
    "from utils.logger import get_logger, log_metrics_for_features\n",
    "from utils.plot_generator import plot_multiagent_trajectories, plot_3d_trajectories_subplots\n",
    "from utils.scaler import scale_per_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044612ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=all\n",
    "# Data settings and parameters\n",
    "DATA_TYPE = \"simulated\"  # Options: \"zurich\", \"quadcopter\", \"mixed\", \"simulated\"\n",
    "SEQUENTIAL_PREDICTION = (\n",
    "    True  # If False, model predicts only the last point for FORWARD_LEN steps\n",
    ")\n",
    "EMBEDDING_EXTRACTION = True\n",
    "AGENTS = 6  # Number of agents or drones\n",
    "LOOK_BACK = 50  # Number of past time steps to use as input\n",
    "if EMBEDDING_EXTRACTION:\n",
    "    FORWARD_LEN = 50 # Prediction is the same as LOOK_BACK for embedding extraction\n",
    "else:\n",
    "    FORWARD_LEN = 5  # Number of future time steps to predict\n",
    "FEATURES_PER_AGENT = 6  # x, y, z, vx, vy, vz, ax, ay, az\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Plotting parameters\n",
    "NUM_PLOTS = 2  # number of plots to generate\n",
    "NUM_SUBPLOTS = 2  # number of subplots to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc6e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 17:13:01,207 - INFO - Experiment started\n",
      "2025-11-04 17:13:01,208 - INFO - Experiment folder: experiments/20251104_171301\n",
      "2025-11-04 17:13:01,209 - INFO - Dataset: simulated\n",
      "2025-11-04 17:13:01,210 - INFO - Number of drones (agents): 6\n",
      "2025-11-04 17:13:01,211 - INFO - LOOK_BACK (past steps): 50\n",
      "2025-11-04 17:13:01,212 - INFO - FORWARD_LEN (future steps): 5\n",
      "2025-11-04 17:13:01,212 - INFO - SEQUENTIAL_PREDICTION: True\n"
     ]
    }
   ],
   "source": [
    "# Setup logger and experiment folder\n",
    "logger, exp_dir = get_logger()\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "logger.info(\"Experiment started\")\n",
    "logger.info(\"Experiment folder: %s\", exp_dir)\n",
    "logger.info(\"Dataset: %s\", DATA_TYPE)\n",
    "logger.info(\"Number of drones (agents): %d\", AGENTS)\n",
    "logger.info(\"LOOK_BACK (past steps): %d\", LOOK_BACK)\n",
    "logger.info(\"FORWARD_LEN (future steps): %d\", FORWARD_LEN)\n",
    "logger.info(\"SEQUENTIAL_PREDICTION: %s\", \"True\" if SEQUENTIAL_PREDICTION else \"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a92da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27894, 55)\n"
     ]
    }
   ],
   "source": [
    "# Load DataFrame\n",
    "df = load_dataset(\n",
    "    DATA_TYPE,\n",
    "    min_rows=800,\n",
    "    num_flights=AGENTS,\n",
    "    features_per_agent=FEATURES_PER_AGENT,\n",
    ")\n",
    "print(df.shape)\n",
    "\n",
    "# Prepare sequences\n",
    "# Track trajectory indices to be used in plotting later\n",
    "X, y, trajectory_ids = [], [], []\n",
    "\n",
    "for traj_idx in df[\"trajectory_index\"].unique():\n",
    "    traj_df = df[df[\"trajectory_index\"] == traj_idx].reset_index(drop=True)\n",
    "\n",
    "    # Drop trajectory_index for features\n",
    "    traj_data = traj_df.drop(columns=[\"trajectory_index\"]).values.astype(np.float32)\n",
    "    n_rows = traj_data.shape[0]\n",
    "\n",
    "    seq_count = n_rows - LOOK_BACK - FORWARD_LEN + 1\n",
    "    for i in range(seq_count):\n",
    "        seq_X = traj_data[i : i + LOOK_BACK]  # shape (LOOK_BACK, features)\n",
    "\n",
    "        # For sequential prediction, predict FORWARD_LEN steps; else just the last step\n",
    "        if EMBEDDING_EXTRACTION is False:\n",
    "            if SEQUENTIAL_PREDICTION:\n",
    "                seq_y = traj_data[\n",
    "                    i + LOOK_BACK : i + LOOK_BACK + FORWARD_LEN\n",
    "                ]  # shape (FORWARD_LEN, features)\n",
    "            else:\n",
    "                seq_y = traj_data[\n",
    "                    i + LOOK_BACK + FORWARD_LEN - 1 : i + LOOK_BACK + FORWARD_LEN\n",
    "                ]  # (1, features)\n",
    "        else:\n",
    "            seq_y = seq_X.copy()  # For embedding extraction, target is same as input\n",
    "\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        trajectory_ids.append(traj_idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8bd8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays\n",
    "X = np.array(X, dtype=np.float32)  # (num_sequences, LOOK_BACK, features)\n",
    "y = np.array(\n",
    "    y, dtype=np.float32\n",
    ")  # (num_sequences, 1, features) or (num_sequences, FORWARD_LEN, features)\n",
    "trajectory_ids = np.array(trajectory_ids)\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test, traj_train, traj_test = train_test_split(\n",
    "    X, y, trajectory_ids, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# Get feature dimension dynamically\n",
    "num_features_X = X_train.shape[-1]\n",
    "\n",
    "# Scale data to [0, 1]\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit scalers on training data only\n",
    "X_train_scaled = scale_per_agent(X_train, scaler_X, FEATURES_PER_AGENT, fit=True)\n",
    "X_test_scaled = scale_per_agent(X_test, scaler_X, FEATURES_PER_AGENT, fit=False)\n",
    "\n",
    "y_train_scaled = scale_per_agent(y_train, scaler_y, FEATURES_PER_AGENT, fit=True)\n",
    "y_test_scaled = scale_per_agent(y_test, scaler_y, FEATURES_PER_AGENT, fit=False)\n",
    "\n",
    "# Save scalers\n",
    "joblib.dump(scaler_X, os.path.join(exp_dir, \"scaler_X.pkl\"))\n",
    "joblib.dump(scaler_y, os.path.join(exp_dir, \"scaler_y.pkl\"))\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(\n",
    "    X_train_scaled, dtype=torch.float32\n",
    ")  # (num_sequences, LOOK_BACK, features)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train_tensor, y_train_tensor), batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(X_test_tensor, y_test_tensor), batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "922def7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 17:13:02,056 - INFO - Total sequences: 27840\n",
      "2025-11-04 17:13:02,058 - INFO - Train sequences: torch.Size([22272, 50, 54])\n",
      "2025-11-04 17:13:02,059 - INFO - Test sequences: torch.Size([5568, 50, 54])\n",
      "2025-11-04 17:13:02,059 - INFO - Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Log dataset sizes\n",
    "total_sequences = X_train_tensor.shape[0] + X_test_tensor.shape[0]\n",
    "logger.info(\"Total sequences: %d\", total_sequences)\n",
    "logger.info(\"Train sequences: %s\", X_train_tensor.shape)\n",
    "logger.info(\"Test sequences: %s\", X_test_tensor.shape)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(\"Using device: %s\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a11b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 17:13:02,844 - INFO - Model module: models.attention_bi_gru_predictor\n",
      "2025-11-04 17:13:02,844 - INFO - Model architecture:\n",
      "TrajPredictor(\n",
      "  (encoder): GRU(9, 128, batch_first=True, bidirectional=True)\n",
      "  (attention): Attention(\n",
      "    (attn): Linear(in_features=384, out_features=128, bias=True)\n",
      "    (v): Linear(in_features=128, out_features=1, bias=False)\n",
      "  )\n",
      "  (enc_to_dec): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (decoder): GRU(265, 128, batch_first=True)\n",
      "  (fc_out): Linear(in_features=128, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model, criterion, optimizer\n",
    "model_params = {\n",
    "    \"input_size\": FEATURES_PER_AGENT,\n",
    "    \"enc_hidden_size\": 64,\n",
    "    \"dec_hidden_size\": 64,\n",
    "    \"num_layers\": 1,\n",
    "}\n",
    "model = TrajPredictor(**model_params).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Log model info\n",
    "logger.info(\"Model module: %s\", model.__class__.__module__)\n",
    "logger.info(\"Model architecture:\\n%s\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c35e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 17:16:31,150 - INFO - Epoch 1/500 - Train Loss: 0.0023183\n",
      "2025-11-04 17:19:58,825 - INFO - Epoch 2/500 - Train Loss: 0.0000705\n",
      "2025-11-04 17:23:29,290 - INFO - Epoch 3/500 - Train Loss: 0.0000619\n",
      "2025-11-04 17:26:57,360 - INFO - Epoch 4/500 - Train Loss: 0.0000587\n",
      "2025-11-04 17:30:45,533 - INFO - Epoch 5/500 - Train Loss: 0.0000565\n",
      "2025-11-04 17:34:37,781 - INFO - Epoch 6/500 - Train Loss: 0.0000577\n",
      "2025-11-04 17:38:33,657 - INFO - Epoch 7/500 - Train Loss: 0.0000552\n",
      "2025-11-04 17:42:28,006 - INFO - Epoch 8/500 - Train Loss: 0.0000553\n",
      "2025-11-04 17:46:21,608 - INFO - Epoch 9/500 - Train Loss: 0.0000541\n",
      "2025-11-04 17:50:27,207 - INFO - Epoch 10/500 - Train Loss: 0.0000536\n",
      "2025-11-04 17:54:20,894 - INFO - Epoch 11/500 - Train Loss: 0.0000507\n",
      "2025-11-04 17:58:14,437 - INFO - Epoch 12/500 - Train Loss: 0.0000509\n",
      "2025-11-04 18:02:10,396 - INFO - Epoch 13/500 - Train Loss: 0.0000494\n",
      "2025-11-04 18:06:07,591 - INFO - Epoch 14/500 - Train Loss: 0.0000493\n",
      "2025-11-04 18:06:41,978 - WARNING - Training interrupted by user! Running evaluation...\n",
      "2025-11-04 18:06:41,986 - INFO - Training finished without early stopping.\n",
      "2025-11-04 18:06:41,986 - INFO - Total training time: 3219.14 seconds\n"
     ]
    }
   ],
   "source": [
    "# Log training time\n",
    "training_start = time.time()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10\n",
    "best_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Training Loop\n",
    "model.train()\n",
    "try:\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch_x, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Add prediction_len argument if sequential prediction\n",
    "            if SEQUENTIAL_PREDICTION:\n",
    "                pred = model(batch_x, pred_len=FORWARD_LEN)\n",
    "            else:\n",
    "                pred = model(batch_x, pred_len=1)\n",
    "\n",
    "            loss = criterion(pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        logger.info(\"Epoch %d/%d - Train Loss: %.7f\", epoch + 1, EPOCHS, avg_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), os.path.join(exp_dir, \"best_model.pt\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # If no improvement for 'patience' epochs, stop training\n",
    "        if epochs_no_improve >= patience:\n",
    "            logger.info(\"Early stopping triggered after %d epochs\", epoch + 1)\n",
    "            early_stop = True\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.warning(\"Training interrupted by user! Running evaluation...\")\n",
    "\n",
    "# Save last-epoch model\n",
    "finally:\n",
    "    torch.save(model.state_dict(), os.path.join(exp_dir, \"last_model.pt\"))\n",
    "\n",
    "# If training completed without early stopping\n",
    "if not early_stop:\n",
    "    logger.info(\"Training finished without early stopping.\")\n",
    "\n",
    "# Log total training time\n",
    "training_end_time = time.time()\n",
    "elapsed_time = training_end_time - training_start\n",
    "logger.info(\"Total training time: %.2f seconds\", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7de84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 18:07:06,735 - INFO - Test Loss (scaled): 0.0000529\n",
      "2025-11-04 18:07:06,736 - INFO - Average inference time per sequence: 0.004007 seconds\n",
      "2025-11-04 18:07:06,736 - INFO - Average inference time per batch: 0.128212 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluation parameters\n",
    "all_preds, all_trues = [], []\n",
    "inference_times = []\n",
    "test_loss = 0.0\n",
    "total_sequences = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        total_sequences += batch_x.size(0)\n",
    "\n",
    "        # Measure inference time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Add prediction_len argument if sequential prediction\n",
    "        if SEQUENTIAL_PREDICTION:\n",
    "            outputs = model(batch_x, pred_len=FORWARD_LEN)\n",
    "        else:\n",
    "            outputs = model(batch_x, pred_len=1)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Record inference time per batch\n",
    "        inference_times.append(end_time - start_time)\n",
    "\n",
    "        # Compute test loss\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Store predictions and true values\n",
    "        all_preds.append(outputs.cpu())\n",
    "        all_trues.append(batch_y.cpu())\n",
    "\n",
    "# Compute average test loss\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "# Compute total inference time, average inference time per batch and per sequence\n",
    "total_inf_time = sum(inference_times)\n",
    "avg_inf_time_per_seq = total_inf_time / total_sequences\n",
    "avg_inf_time_per_batch = total_inf_time / len(test_loader)\n",
    "\n",
    "# Log final test metrics\n",
    "logger.info(\"Test Loss (scaled): %.7f\", avg_test_loss)\n",
    "logger.info(\"Average inference time per sequence: %.6f seconds\", avg_inf_time_per_seq)\n",
    "logger.info(\"Average inference time per batch: %.6f seconds\", avg_inf_time_per_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05586c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 18:07:28,163 - INFO - ------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2025-11-04 18:07:28,164 - INFO - Timestep |        EDE |    Pos_MSE |   Pos_RMSE |    Pos_MAE |    Vel_MSE |   Vel_RMSE |    Vel_MAE |    Acc_MSE |   Acc_RMSE |    Acc_MAE\n",
      "2025-11-04 18:07:28,164 - INFO - ------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2025-11-04 18:07:28,165 - INFO -        0 |   0.389369 |   0.178855 |   0.422913 |   0.176450 |   0.010790 |   0.103877 |   0.066555 |   3.696356 |   1.922591 |   0.802852\n",
      "2025-11-04 18:07:28,165 - INFO -        1 |   0.365166 |   0.286486 |   0.535244 |   0.172274 |   0.015148 |   0.123077 |   0.073415 |   3.587385 |   1.894039 |   0.828413\n",
      "2025-11-04 18:07:28,166 - INFO -        2 |   0.371952 |   0.403226 |   0.635001 |   0.178672 |   0.021284 |   0.145889 |   0.083912 |   3.560524 |   1.886935 |   0.821494\n",
      "2025-11-04 18:07:28,166 - INFO -        3 |   0.373140 |   0.518710 |   0.720216 |   0.180230 |   0.028752 |   0.169565 |   0.094231 |   3.669567 |   1.915611 |   0.843018\n",
      "2025-11-04 18:07:28,166 - INFO -        4 |   0.378149 |   0.634319 |   0.796442 |   0.183602 |   0.037200 |   0.192872 |   0.103497 |   3.790373 |   1.946888 |   0.872296\n",
      "2025-11-04 18:07:28,167 - INFO - ------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2025-11-04 18:07:28,168 - INFO -  Average |   0.375555 |   0.404320 |   0.621963 |   0.178246 |   0.022635 |   0.147056 |   0.084322 |   3.660841 |   1.913213 |   0.833615\n",
      "2025-11-04 18:07:28,168 - INFO - ------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all batches\n",
    "y_pred = torch.cat(all_preds, dim=0)\n",
    "y_true = torch.cat(all_trues, dim=0)\n",
    "\n",
    "log_metrics_for_features(\n",
    "    y_true, y_pred, scaler_y, AGENTS, FEATURES_PER_AGENT, logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2661fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 18:07:57,588 - INFO - Config saved to experiments/20251104_171301/config.json\n"
     ]
    }
   ],
   "source": [
    "# Save config / hyperparameters\n",
    "config = {\n",
    "    \"device\": str(device),\n",
    "    \"model_module\": model.__class__.__module__,\n",
    "    \"model_class\": model.__class__.__name__,\n",
    "    \"model_params\": model_params,\n",
    "    \"DATA_TYPE\": DATA_TYPE,\n",
    "    \"AGENTS\": AGENTS,\n",
    "    \"FEATURES_PER_AGENT\": FEATURES_PER_AGENT,\n",
    "    \"LOOK_BACK\": LOOK_BACK,\n",
    "    \"FORWARD_LEN\": FORWARD_LEN,\n",
    "    \"SEQUENTIAL_PREDICTION\": SEQUENTIAL_PREDICTION,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "}\n",
    "\n",
    "config_path = os.path.join(exp_dir, \"config.json\")\n",
    "with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "logger.info(\"Config saved to %s\", config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group results back by trajectory_index\n",
    "traj_test = traj_test[: len(y_true)]  # align just in case\n",
    "unique_trajs = np.unique(traj_test)\n",
    "\n",
    "# Randomly select trajectories to plot\n",
    "plot_trajs = np.random.choice(\n",
    "    unique_trajs, size=min(NUM_PLOTS, len(unique_trajs)), replace=False\n",
    ").tolist()\n",
    "\n",
    "# Plot trajectories using the helper function\n",
    "plot_multiagent_trajectories(\n",
    "    y_true=y_true.numpy(),\n",
    "    y_pred=y_pred.numpy(),\n",
    "    traj_ids=traj_test,\n",
    "    plot_trajs=plot_trajs,\n",
    "    scaler=scaler_y,\n",
    "    features_per_agent=FEATURES_PER_AGENT,\n",
    "    save_dir=exp_dir,\n",
    "    velocity_scale=0.5,\n",
    "    acceleration_scale=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all past inputs (for context)\n",
    "past_inputs = torch.cat(\n",
    "    [b for b, _ in test_loader], dim=0\n",
    ").numpy()  # (num_sequences, LOOK_BACK, num_features)\n",
    "\n",
    "# Ensure NUM_PLOTS does not exceed number of sequences\n",
    "num_sequences = y_true.shape[0]\n",
    "NUM_SUBPLOTS = min(NUM_SUBPLOTS, num_sequences)\n",
    "\n",
    "# Randomly select sequence indices for plotting\n",
    "plot_indices = np.random.choice(num_sequences, size=NUM_SUBPLOTS, replace=False)\n",
    "\n",
    "trajectory_sets = []\n",
    "\n",
    "for seq_idx in plot_indices:\n",
    "    past = past_inputs[seq_idx]  # shape: (LOOK_BACK, features)\n",
    "    true_future = y_true[seq_idx]  # shape: (seq_len, features)\n",
    "    pred_future = y_pred[seq_idx]  # shape: (seq_len, features)\n",
    "\n",
    "    # Inverse scale past and future\n",
    "    past_orig = scale_per_agent(past, scaler_X, FEATURES_PER_AGENT, inverse=True)\n",
    "    true_future_orig = scale_per_agent(\n",
    "        true_future, scaler_y, FEATURES_PER_AGENT, inverse=True\n",
    "    )\n",
    "    pred_future_orig = scale_per_agent(\n",
    "        pred_future, scaler_y, FEATURES_PER_AGENT, inverse=True\n",
    "    )\n",
    "\n",
    "    # Concatenate last past point with future to make continuous lines\n",
    "    true_line = np.vstack([past_orig[-1:], true_future_orig])\n",
    "    pred_line = np.vstack([past_orig[-1:], pred_future_orig])\n",
    "\n",
    "    trajectory_sets.append((past_orig, true_line, pred_line))\n",
    "\n",
    "# Create subplots for selected sequences\n",
    "plot_path = Path(exp_dir) / \"training_subplots.png\"\n",
    "plot_3d_trajectories_subplots(\n",
    "    trajectory_sets,\n",
    "    per_agent=True,\n",
    "    num_features=FEATURES_PER_AGENT,            # Enable velocity + acceleration\n",
    "    velocity_scale=0.5,        # Adjust arrow length\n",
    "    acceleration_scale=0.3,    # Adjust arrow length\n",
    "    save_path=str(plot_path)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

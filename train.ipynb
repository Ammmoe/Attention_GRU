{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data.trajectory_loader import load_dataset\n",
    "from models.attention_bi_gru_predictor import TrajPredictor\n",
    "from utils.logger import get_logger\n",
    "from utils.model_evaluator import evaluate_metrics_multi_agent as evaluate\n",
    "from utils.plot_generator import plot_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044612ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=all\n",
    "# Data settings and parameters\n",
    "DATA_TYPE = \"mixed\"  # Options: \"zurich\", \"quadcopter\", \"mixed\"\n",
    "AGENTS = 3  # Number of agents or drones\n",
    "LOOK_BACK = 50  # Number of past time steps to use as input\n",
    "FORWARD_LEN = 5  # Number of future time steps to predict\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Plotting parameters\n",
    "NUM_PLOTS = 3  # number of plots to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logger and experiment folder\n",
    "logger, exp_dir = get_logger()\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "logger.info(\"Experiment started\")\n",
    "logger.info(\"Experiment folder: %s\", exp_dir)\n",
    "logger.info(\"Dataset used: %s\", DATA_TYPE)\n",
    "logger.info(\"Number of drones: %d\", AGENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "df = load_dataset(\n",
    "    DATA_TYPE,\n",
    "    min_rows=800,\n",
    "    num_flights=AGENTS,\n",
    ")\n",
    "\n",
    "# Prepare sequences\n",
    "# Track trajectory indices to be used in plotting later\n",
    "X, y, trajectory_ids = [], [], []\n",
    "\n",
    "for traj_idx in df[\"trajectory_index\"].unique():\n",
    "    traj_df = df[df[\"trajectory_index\"] == traj_idx].reset_index(drop=True)\n",
    "\n",
    "    # Drop trajectory_index for features\n",
    "    traj_data = traj_df.drop(columns=[\"trajectory_index\"]).values.astype(np.float32)\n",
    "    n_rows = traj_data.shape[0]\n",
    "\n",
    "    seq_count = n_rows - LOOK_BACK - FORWARD_LEN + 1\n",
    "    for i in range(seq_count):\n",
    "        seq_X = traj_data[i : i + LOOK_BACK]  # shape (LOOK_BACK, features)\n",
    "        seq_y = traj_data[i + LOOK_BACK + FORWARD_LEN - 1]  # shape (features,)\n",
    "\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        trajectory_ids.append(traj_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays\n",
    "X = np.array(X, dtype=np.float32)  # (num_sequences, LOOK_BACK, features)\n",
    "y = np.array(y, dtype=np.float32)  # (num_sequences, features)\n",
    "trajectory_ids = np.array(trajectory_ids)\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test, traj_train, traj_test = train_test_split(\n",
    "    X, y, trajectory_ids, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# Get feature dimension dynamically\n",
    "num_features_X = X_train.shape[-1]\n",
    "\n",
    "# Scale data to [0, 1]\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit scalers on training data only\n",
    "# X needs to be reshaped to 2D for scaler\n",
    "scaler_X.fit(X_train.reshape(-1, num_features_X))\n",
    "X_train_scaled = scaler_X.transform(X_train.reshape(-1, num_features_X)).reshape(\n",
    "    X_train.shape\n",
    ")\n",
    "X_test_scaled = scaler_X.transform(X_test.reshape(-1, num_features_X)).reshape(\n",
    "    X_test.shape\n",
    ")\n",
    "\n",
    "# y is already 2D\n",
    "scaler_y.fit(y_train)\n",
    "y_train_scaled = scaler_y.transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(\n",
    "    X_train_scaled, dtype=torch.float32\n",
    ")  # (num_sequences, LOOK_BACK, features)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train_tensor, y_train_tensor), batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(X_test_tensor, y_test_tensor), batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922def7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log dataset sizes\n",
    "total_sequences = X_train_tensor.shape[0] + X_test_tensor.shape[0]\n",
    "logger.info(\"Total sequences: %d\", total_sequences)\n",
    "logger.info(\"Train sequences: %s\", X_train_tensor.shape)\n",
    "logger.info(\"Test sequences: %s\", X_test_tensor.shape)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(\"Using device: %s\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, criterion, optimizer\n",
    "model_params = {\n",
    "    \"input_size\": X_train_tensor.shape[-1],  # features (e.g., 3 for x,y,z)\n",
    "    \"enc_hidden_size\": 64,\n",
    "    \"dec_hidden_size\": 64,\n",
    "    \"output_size\": y_train_tensor.shape[-1],  # same as features\n",
    "    \"num_layers\": 1,\n",
    "}\n",
    "model = TrajPredictor(**model_params).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Log model info\n",
    "logger.info(\"Model module: %s\", model.__class__.__module__)\n",
    "logger.info(\"Model architecture:\\n%s\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c35e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log training time\n",
    "training_start = time.time()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 15\n",
    "best_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Training Loop\n",
    "model.train()\n",
    "try:\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch_x)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        logger.info(\"Epoch %d/%d - Train Loss: %.7f\", epoch + 1, EPOCHS, avg_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), os.path.join(exp_dir, \"best_model.pt\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # If no improvement for 'patience' epochs, stop training\n",
    "        if epochs_no_improve >= patience:\n",
    "            logger.info(\"Early stopping triggered after %d epochs\", epoch + 1)\n",
    "            early_stop = True\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.warning(\"Training interrupted by user! Running evaluation...\")\n",
    "\n",
    "# Save last-epoch model\n",
    "finally:\n",
    "    torch.save(model.state_dict(), os.path.join(exp_dir, \"last_model.pt\"))\n",
    "\n",
    "# If training completed without early stopping\n",
    "if not early_stop:\n",
    "    logger.info(\"Training finished without early stopping.\")\n",
    "\n",
    "# Log total training time\n",
    "training_end_time = time.time()\n",
    "elapsed_time = training_end_time - training_start\n",
    "logger.info(\"Total training time: %.2f seconds\", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation parameters\n",
    "all_preds, all_trues = [], []\n",
    "inference_times = []\n",
    "test_loss = 0.0\n",
    "total_sequences = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        total_sequences += batch_x.size(0)\n",
    "\n",
    "        start_time = time.time()\n",
    "        outputs = model(batch_x)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Record inference time per batch\n",
    "        inference_times.append(end_time - start_time)\n",
    "\n",
    "        # Compute test loss\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Store predictions and true values\n",
    "        all_preds.append(outputs.cpu())\n",
    "        all_trues.append(batch_y.cpu())\n",
    "\n",
    "# Compute average test loss\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "# Compute total inference time, average inference time per batch and per sequence\n",
    "total_inf_time = sum(inference_times)\n",
    "avg_inf_time_per_seq = total_inf_time / total_sequences\n",
    "avg_inf_time_per_batch = total_inf_time / len(test_loader)\n",
    "\n",
    "# Log final test metrics\n",
    "logger.info(\"Test Loss (scaled): %.7f\", avg_test_loss)\n",
    "logger.info(\"Average inference time per sequence: %.6f seconds\", avg_inf_time_per_seq)\n",
    "logger.info(\"Average inference time per batch: %.6f seconds\", avg_inf_time_per_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05586c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all batches\n",
    "y_pred = torch.cat(all_preds, dim=0)\n",
    "y_true = torch.cat(all_trues, dim=0)\n",
    "\n",
    "# Compute evaluation metrics (inverse scaling applied)\n",
    "mse, rmse, mae, ede, axis_mse, axis_rmse, axis_mae = evaluate(\n",
    "    y_true, y_pred, scaler_y, num_agents=AGENTS\n",
    ")\n",
    "\n",
    "mse_x, mse_y, mse_z = axis_mse\n",
    "rmse_x, rmse_y, rmse_z = axis_rmse\n",
    "mae_x, mae_y, mae_z = axis_mae\n",
    "\n",
    "# Log metrics per axis and overall\n",
    "logger.info(\n",
    "    \"Test Mean Squared Error (MSE) per axis (averaged over %d agents): x=%.6f, y=%.6f, z=%.6f meters^2\",\n",
    "    AGENTS,\n",
    "    mse_x,\n",
    "    mse_y,\n",
    "    mse_z,\n",
    ")\n",
    "logger.info(\"Test Mean Squared Error (MSE) overall: %.6f meters^2\", mse)\n",
    "\n",
    "logger.info(\n",
    "    \"Test Root Mean Squared Error (RMSE) per axis (averaged over %d agents): x=%.6f, y=%.6f, z=%.6f meters\",\n",
    "    AGENTS,\n",
    "    rmse_x,\n",
    "    rmse_y,\n",
    "    rmse_z,\n",
    ")\n",
    "logger.info(\"Test Root Mean Squared Error (RMSE) overall: %.6f meters\", rmse)\n",
    "\n",
    "logger.info(\n",
    "    \"Test Mean Absolute Error (MAE) per axis (averaged over %d agents): x=%.6f, y=%.6f, z=%.6f meters\",\n",
    "    AGENTS,\n",
    "    mae_x,\n",
    "    mae_y,\n",
    "    mae_z,\n",
    ")\n",
    "logger.info(\"Test Mean Absolute Error (MAE) overall: %.6f meters\", mae)\n",
    "\n",
    "logger.info(\n",
    "    \"Test Euclidean Distance Error (EDE) (averaged over all agents): %.6f meters\", ede\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config / hyperparameters\n",
    "config = {\n",
    "    \"device\": str(device),\n",
    "    \"model_module\": model.__class__.__module__,\n",
    "    \"model_class\": model.__class__.__name__,\n",
    "    \"model_params\": model_params,\n",
    "    \"DATA_TYPE\": DATA_TYPE,\n",
    "    \"AGENTS\": AGENTS,\n",
    "    \"LOOK_BACK\": LOOK_BACK,\n",
    "    \"FORWARD_LEN\": FORWARD_LEN,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "}\n",
    "\n",
    "config_path = os.path.join(exp_dir, \"config.json\")\n",
    "with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "logger.info(\"Config saved to %s\", config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group results back by trajectory_index\n",
    "traj_test = traj_test[: len(y_true)]  # align just in case\n",
    "unique_trajs = np.unique(traj_test)\n",
    "\n",
    "# Randomly select trajectories to plot\n",
    "plot_trajs = np.random.choice(\n",
    "    unique_trajs, size=min(NUM_PLOTS, len(unique_trajs)), replace=False\n",
    ").tolist()\n",
    "\n",
    "# Plot trajectories using the helper function\n",
    "plot_trajectories(\n",
    "    y_true=y_true.numpy(),\n",
    "    y_pred=y_pred.numpy(),\n",
    "    traj_ids=traj_test,\n",
    "    plot_trajs=plot_trajs,\n",
    "    scaler=scaler_y,\n",
    "    agents=AGENTS,\n",
    "    save_dir=exp_dir,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
